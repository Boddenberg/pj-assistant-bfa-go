# PJ Assistant â€” BFA (Go) + AI Agent (Python/LangGraph)

> Assistente inteligente para clientes PJ do ItaÃº, combinando um Backend For App (BFA) em Go com um Agente de IA Generativa baseado em LangGraph.

## ğŸ“ Estrutura do Projeto

```
pj-assistant-bfa-go/
â”‚
â”œâ”€â”€ cmd/bfa/                        # Entrypoint do BFA (Go)
â”‚   â””â”€â”€ main.go
â”‚
â”œâ”€â”€ internal/                       # CÃ³digo interno do BFA
â”‚   â”œâ”€â”€ config/                     # ConfiguraÃ§Ã£o (env vars)
â”‚   â”œâ”€â”€ domain/                     # Modelos de domÃ­nio e erros
â”‚   â”œâ”€â”€ handler/                    # HTTP handlers e router (chi)
â”‚   â”œâ”€â”€ port/                       # Interfaces (ports) â€” hexagonal
â”‚   â”œâ”€â”€ service/                    # LÃ³gica de orquestraÃ§Ã£o
â”‚   â””â”€â”€ infra/                      # ImplementaÃ§Ãµes de infraestrutura
â”‚       â”œâ”€â”€ cache/                  # Cache in-memory com TTL
â”‚       â”œâ”€â”€ client/                 # Clientes HTTP (Profile, Transactions, Agent)
â”‚       â”œâ”€â”€ observability/          # MÃ©tricas (Prometheus), Tracing (OTel), Logging (Zap)
â”‚       â””â”€â”€ resilience/             # Retry, Circuit Breaker, Bulkhead
â”‚
â”œâ”€â”€ agent/                          # Agente de IA (Python)
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ server.py               # FastAPI server
â”‚   â”‚   â”œâ”€â”€ config.py               # ConfiguraÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ models.py               # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ graph.py                # LangGraph workflow
â”‚   â”‚   â”œâ”€â”€ security.py             # SeguranÃ§a e governanÃ§a
â”‚   â”‚   â”œâ”€â”€ observability.py        # MÃ©tricas Prometheus
â”‚   â”‚   â”œâ”€â”€ nodes/                  # NÃ³s do grafo do agente
â”‚   â”‚   â”‚   â”œâ”€â”€ planner.py          # Planner â€” decide os passos
â”‚   â”‚   â”‚   â”œâ”€â”€ retriever.py        # Retriever â€” busca RAG
â”‚   â”‚   â”‚   â”œâ”€â”€ analyzer.py         # Analyzer â€” anÃ¡lise financeira
â”‚   â”‚   â”‚   â””â”€â”€ synthesizer.py      # Synthesizer â€” gera recomendaÃ§Ã£o via LLM
â”‚   â”‚   â””â”€â”€ rag/
â”‚   â”‚       â””â”€â”€ retriever.py        # Pipeline RAG (chunking, embeddings, busca)
â”‚   â”œâ”€â”€ data/knowledge_base/        # Base de conhecimento (textos fictÃ­cios)
â”‚   â”œâ”€â”€ tests/                      # Testes do agente
â”‚   â””â”€â”€ pyproject.toml
â”‚
â”œâ”€â”€ deploy/                         # ConfiguraÃ§Ãµes de deploy
â”‚   â””â”€â”€ prometheus.yml
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ ARCHITECTURE.md             # DocumentaÃ§Ã£o arquitetural
â”‚
â”œâ”€â”€ docker-compose.yml              # Stack completa
â”œâ”€â”€ Dockerfile                      # BFA (Go)
â”œâ”€â”€ Makefile                        # Comandos Ãºteis
â””â”€â”€ README.md
```

---

## ğŸš€ Como Rodar Localmente

### PrÃ©-requisitos
- Go 1.22+
- Python 3.11+
- Docker & Docker Compose (opcional)
- Uma API key da OpenAI (para o agente)

### OpÃ§Ã£o 1: Docker Compose (recomendado)

```bash
# Configure a API key
export OPENAI_API_KEY=sk-your-key-here

# Suba toda a stack
docker compose up --build

# Endpoints disponÃ­veis:
# BFA:         http://localhost:8080/v1/assistant/{customerId}
# Agent:       http://localhost:8090/v1/agent/invoke
# Jaeger UI:   http://localhost:16686
# Prometheus:  http://localhost:9090
```

### OpÃ§Ã£o 2: Rodar separadamente

```bash
# Terminal 1 â€” BFA (Go)
export AGENT_API_URL=http://localhost:8090
go run ./cmd/bfa

# Terminal 2 â€” Agent (Python)
cd agent
cp .env.example .env  # Configure sua OPENAI_API_KEY
pip install -e ".[dev]"
uvicorn app.server:app --reload --port 8090
```

---

## ğŸ§ª Como Rodar Testes

```bash
# Testes Go (unitÃ¡rios + race detection)
make test

# Testes Python (unitÃ¡rios + cobertura)
make agent-test

# Todos
make test-all
```

---

## ğŸ— DecisÃµes Arquiteturais

### 1. SeparaÃ§Ã£o BFA (Go) Ã— Agent (Python)
**DecisÃ£o**: Dois serviÃ§os independentes, comunicando via HTTP/JSON.

**Justificativa**:
- Go Ã© ideal para o BFA: I/O concorrente, low-latency, forte tipagem
- Python Ã© o ecossistema dominante em IA: LangChain, LangGraph, modelos de embedding
- SeparaÃ§Ã£o permite escalar independentemente e equipes distintas operarem cada parte

**Trade-off**: Overhead de rede entre serviÃ§os. Em produÃ§Ã£o, poderia usar gRPC para menor latÃªncia.

### 2. Arquitetura Hexagonal (BFA)
**DecisÃ£o**: Domain, Ports, Service, Infra â€” separaÃ§Ã£o clara de responsabilidades.

**Justificativa**:
- Testabilidade: mocks nas interfaces (ports)
- Flexibilidade: trocar implementaÃ§Ãµes sem alterar domÃ­nio
- Clareza: cada pacote tem uma responsabilidade

### 3. LangGraph para o Agente
**DecisÃ£o**: Workflow estruturado como grafo com nÃ³s independentes.

**Justificativa**:
- Grafo explÃ­cito e auditÃ¡vel (vs. chains implÃ­citas)
- Edges condicionais permitem pular etapas desnecessÃ¡rias
- Estado tipado e rastreÃ¡vel entre nÃ³s
- Facilidade para adicionar novos nÃ³s (ex: multiagente)

### 4. RAG com ChromaDB + sentence-transformers
**DecisÃ£o**: Embeddings locais com modelo leve, vector store sem infra externa.

**Justificativa**:
- `all-MiniLM-L6-v2`: roda em CPU, suficiente para demonstraÃ§Ã£o
- ChromaDB: zero infra, persistente em disco
- Chunking de 500 chars com 100 overlap: granularidade adequada para busca precisa

**Trade-off**: Em produÃ§Ã£o, usaria OpenSearch/Pinecone + reranking com cross-encoder.

### 5. ResiliÃªncia no BFA
- **Retry exponencial + jitter**: evita thundering herd
- **Circuit Breaker**: protege contra falhas em cascata
- **Bulkhead**: limita concorrÃªncia, evita resource starvation
- **Context com timeout**: propagado em toda a cadeia de chamadas

### 6. SeguranÃ§a do Agente
- SanitizaÃ§Ã£o no boundary (input cleaning)
- DetecÃ§Ã£o de prompt injection por patterns
- RedaÃ§Ã£o de PII na saÃ­da
- Rate limiting por customer
- Controle de custo diÃ¡rio por customer

---

## âš–ï¸ Trade-offs Assumidos

| DecisÃ£o | Trade-off |
|---------|-----------|
| Cache in-memory (Go) | Simples, mas nÃ£o compartilhado entre instÃ¢ncias. Em prod: Redis/ElastiCache |
| ChromaDB local | Zero infra, mas nÃ£o escala horizontalmente. Em prod: OpenSearch/Pinecone |
| Embeddings em CPU | Lento para grandes volumes. Em prod: GPU ou API de embeddings |
| HTTP entre BFAâ†”Agent | Overhead vs simplicidade. Em prod: gRPC com streaming |
| LLM via OpenAI API | DependÃªncia externa. Em prod: avaliaria modelos on-premise ou Bedrock |
| Prompt injection por regex | Cobertura limitada. Em prod: combinaria com classificador ML |
| MÃ©tricas Prometheus pull | Requer scraping. Em prod: push via OTLP para observabilidade unificada |

---

## ğŸ”„ O Que Faria Diferente em ProduÃ§Ã£o Real

1. **Cache distribuÃ­do**: Redis/ElastiCache ao invÃ©s de in-memory
2. **Vector Store gerenciado**: Amazon OpenSearch com plugin k-NN ou Pinecone
3. **Reranking**: Cross-encoder para reordenar resultados do RAG
4. **gRPC**: ComunicaÃ§Ã£o BFAâ†”Agent com Protocol Buffers
5. **AvaliaÃ§Ã£o de qualidade**: LLM-as-judge para scoring automÃ¡tico de respostas
6. **MLOps pipeline**: Versionamento de prompts, A/B testing de modelos
7. **Event-driven**: SQS/SNS para desacoplar chamadas ao agente quando assÃ­ncrono
8. **Guardrails LLM**: NeMo Guardrails ou similar para governanÃ§a de output
9. **Secrets Manager**: AWS Secrets Manager para API keys
10. **Observabilidade**: LangFuse/LangSmith para tracing especÃ­fico de LLM

---

## ğŸ“Š MÃ©tricas e Qualidade

### MÃ©tricas Implementadas
- `bfa_request_duration_seconds` â€” LatÃªncia do BFA por operaÃ§Ã£o
- `bfa_external_errors_total` â€” Erros de serviÃ§os externos
- `bfa_cache_hits_total` / `bfa_cache_misses_total` â€” Cache hit ratio
- `bfa_llm_tokens_total` â€” Tokens consumidos (prompt/completion)
- `agent_request_duration_seconds` â€” LatÃªncia do agente por step
- `agent_request_cost_usd` â€” Custo estimado por request
- `agent_errors_total` â€” Erros por tipo
- `agent_response_confidence` â€” ConfianÃ§a da resposta
- `agent_fallback_total` â€” Taxa de fallback

### Como Avaliar Qualidade
- **Qualidade de resposta**: LLM-as-judge com rubrics (relevÃ¢ncia, completude, tom)
- **PrecisÃ£o do RAG**: Recall@K e precision medidos contra golden set
- **AlucinaÃ§Ãµes**: VerificaÃ§Ã£o de groundedness â€” resposta baseada nos docs recuperados
- **Drift de modelo**: Monitorar distribuiÃ§Ã£o de confianÃ§a e tokens ao longo do tempo

---

## ğŸ—º EstratÃ©gia de EvoluÃ§Ã£o Futura

1. **Multiagente**: Agentes especializados (crÃ©dito, investimento, risco) orquestrados por um meta-agente
2. **Streaming**: SSE/WebSocket para respostas em tempo real
3. **Memory**: MemÃ³ria de longo prazo por customer (histÃ³rico de interaÃ§Ãµes)
4. **Feedback loop**: Captura de feedback do usuÃ¡rio para fine-tuning
5. **Cache vetorial**: Cache semÃ¢ntico de respostas similares para reduzir custo de LLM
6. **AvaliaÃ§Ã£o contÃ­nua**: Pipeline de avaliaÃ§Ã£o automÃ¡tica em CI/CD

---

## ğŸ“œ LicenÃ§a

Projeto desenvolvido para o case tÃ©cnico â€” uso interno.
